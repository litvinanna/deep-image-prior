{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAKING PICTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "def inpainting(container, cuda = False, iterations = 100):\n",
    "    \n",
    "    seq_np = container.seq_np\n",
    "    mask_np = container.mask_np\n",
    "\n",
    "    if cuda: \n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark =True\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        torch.backends.cudnn.enabled = False\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    PLOT = False\n",
    "    imsize = -1\n",
    "    dim_div_by = 64\n",
    "\n",
    "\n",
    "    pad = 'reflection' # 'zero'\n",
    "    OPT_OVER = 'net'\n",
    "    OPTIMIZER = 'adam'\n",
    "    NET_TYPE = 'skip_depth6'\n",
    "    \n",
    "    INPUT = 'noise'\n",
    "    input_depth = 32\n",
    "    LR = 0.01 \n",
    "    num_iter = iterations\n",
    "    param_noise = False\n",
    "    show_every = 5\n",
    "    figsize = 5 #????\n",
    "    reg_noise_std = 0.03\n",
    "\n",
    "    net = skip(input_depth, seq_np.shape[0], #change skip function in models/skip.py\n",
    "               num_channels_down = [128] * 3,\n",
    "               num_channels_up =   [128] * 3,\n",
    "               num_channels_skip =    [128] * 3,  \n",
    "               filter_size_up = 3, filter_size_down = 3, \n",
    "               upsample_mode='nearest', filter_skip_size=1,\n",
    "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "    \n",
    "    global description\n",
    "    things = [NET_TYPE, pad, OPT_OVER, OPTIMIZER, INPUT, input_depth, LR, num_iter]\n",
    "    description=\"_\".join([str(x) for x in things])\n",
    "\n",
    "    \n",
    "    net = net.type(dtype) \n",
    "    net_input = get_noise(input_depth, INPUT, seq_np.shape[1]).type(dtype) #tensor \n",
    "\n",
    "    \n",
    "    s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "    print ('Number of params: %d' % s)\n",
    "\n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "    # img_var = np_to_torch(img_np).type(dtype)\n",
    "    # mask_var = np_to_torch(img_mask_np).type(dtype)\n",
    "\n",
    "    img_var = np_to_torch(seq_np).type(dtype)\n",
    "    mask_var = np_to_torch(mask_np).type(dtype)\n",
    "    \n",
    "    \n",
    "    def closure():\n",
    "\n",
    "        global i\n",
    "    #     if param_noise:\n",
    "    #         for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "    #             n = n + n.detach().clone().normal_() * n.std() / 50\n",
    "\n",
    "        net_input = net_input_saved\n",
    "        if reg_noise_std > 0:\n",
    "            net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        out = net(net_input)\n",
    "        total_loss = mse(out * mask_var, img_var * mask_var)\n",
    "        total_loss.backward()\n",
    "        print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    p = get_params(OPT_OVER, net, net_input) # list of tensors to optimize over !! in optimize\n",
    "    loss = optimize(OPTIMIZER, p, closure, LR, num_iter) # optimize is in utils/common.utils\n",
    "    out_np = torch_to_np(net(net_input))\n",
    "\n",
    "    \n",
    "    return out_np, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import random \n",
    "\n",
    "from Bio import SeqIO\n",
    "import math\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "fasta_file = \"data/myco_genome.fasta\"\n",
    "local_genome = \"/Users/pochtalionizm/Projects/neuro/data/GCF_000195955.2_ASM19595v2_genomic.gbff\"\n",
    "remote_genome = \"data/myco_genome.gbff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Container:\n",
    "    def __init__(self):\n",
    "        self.record = None #Seq??\n",
    "        self.length = None #int\n",
    "        self.seq = None #np.array of chars\n",
    "        self.seq_np = None #np.array of [1, 0, 0, 0]\n",
    "        self.out_seq = None #np.array of chars\n",
    "        self.out_array = None #np.array of [1, 0, 0, 0]\n",
    "        \n",
    "        \n",
    "        self.bases_dict     = {\"A\": 0, \"T\": 1, \"C\": 2, \"G\": 3}\n",
    "        self.bases_list = [\"A\", \"T\", \"C\", \"G\"]\n",
    "        self.bases_np        = {\"A\": np.array([1, 0, 0, 0], dtype = np.float32),\n",
    "                             \"T\": np.array([0, 1, 0, 0], dtype = np.float32),\n",
    "                             \"C\": np.array([0, 0, 1, 0], dtype = np.float32),\n",
    "                             \"G\": np.array([0, 0, 0, 1], dtype = np.float32)\n",
    "                            }\n",
    "        self.freqs = None # dict {'A':0.34, ...}\n",
    "        self.counter = {}\n",
    "        print(\"container created\")\n",
    "        \n",
    "        \n",
    "    def read_seq(self, genome_file = remote_genome, genome_file_type = \"genbank\"):\n",
    "        iterator = SeqIO.parse(genome_file, genome_file_type)\n",
    "        self.record = next(iterator)\n",
    "        self.seq = np.asarray(self.record.seq) \n",
    "        \n",
    "        print(\"read seq from file {}, length = {}\".format(genome_file, len(self.record.seq)))\n",
    "    \n",
    "    def generate_seq(self, length = None):\n",
    "        if length == None:\n",
    "            length = len(self.record.seq)\n",
    "        seq_np = np.zeros((4, length), dtype = np.float32)\n",
    "        for index in range(length):\n",
    "            base = self.seq[index]\n",
    "            channel = self.bases_dict[base]\n",
    "            seq_np[channel][index] = 1\n",
    "            \n",
    "            \n",
    "        self.length = length\n",
    "        self.seq_np = seq_np\n",
    "        \n",
    "        print(\"generated seq for analysis, length = {}\".format(self.length))\n",
    "        \n",
    "    def generate_mask(self, seed=False):\n",
    "        length = self.length\n",
    "        length_mask = math.ceil(self.length * 0.1)\n",
    "        \n",
    "        if seed:\n",
    "            random.seed(7)\n",
    "        mask_np = np.zeros((4, length), dtype=np.float32)\n",
    "        mask = np.zeros(length)\n",
    "        \n",
    "        mask_np.fill(1)\n",
    "        for n in range(length_mask):\n",
    "            spot = 1\n",
    "            index = random.randint(0, length-spot)\n",
    "            for i in range(index, index+spot):\n",
    "                mask_np[:, i] = [0,0,0,0]\n",
    "                mask[i] = 1\n",
    "                \n",
    "        self.mask_np = mask_np\n",
    "        self.length_mask = int(sum(mask)) # true mask length!!\n",
    "        self.mask = mask\n",
    "\n",
    "        print(\"generated mask with {} spots of {} bp, seed {}\".format(self.length_mask, spot, seed))\n",
    "        \n",
    "    def inpaint(self, out_np = None):\n",
    "        if out_np is None:\n",
    "            self.out_np = inpainting(self)\n",
    "        else:\n",
    "            self.out_np = out_np\n",
    "            print(\"assigned inpainted array\")\n",
    "            \n",
    "    \n",
    "    def _get_freqs(self):\n",
    "        counter = Counter(self.seq[0:self.length])\n",
    "        self.freqs = {letter : value / self.length for (letter, value) in counter.items()}\n",
    "    \n",
    "    def _baseline(self): #count mistakes under mask if using random predictor with frequences\n",
    "        counter = 0\n",
    "        for i in range(self.length):\n",
    "            if self.mask[i] == 1: #if its under mask\n",
    "                w = [self.freqs[x] for x in self.bases_list]\n",
    "                letter = random.choices(self.bases_list, weights=w)[0]\n",
    "                if letter != self.seq[i]:\n",
    "                        counter +=1\n",
    "        return counter\n",
    "    \n",
    "    \n",
    "    def baseline(self):\n",
    "        self._get_freqs()\n",
    "        baselines = []\n",
    "        for i in range(100):\n",
    "            baselines.append(self._baseline())\n",
    "        mean = np.mean(baselines)\n",
    "        sd = np.std(baselines)\n",
    "        self.counter[\"baseline_mean\"] = mean\n",
    "        self.counter[\"baseline_sd\"] = sd\n",
    "        print(\"got baseline\")\n",
    "\n",
    "    def generate_out(self): \n",
    "        \n",
    "        out_seq = np.zeros(self.length, dtype= \"U8\")\n",
    "        for i in range(self.length):\n",
    "            channel = np.argmax(self.out_np[:, i])\n",
    "            out_seq[i] = self.bases_list[channel] \n",
    "            \n",
    "        out_array = np.zeros((4,self.length)) #array analog to seq_np\n",
    "        for i in range(self.length):\n",
    "            n = np.argmax(self.out_np[:, i])\n",
    "            out_array[n, i] = 1\n",
    "            \n",
    "        self.out_seq = out_seq\n",
    "        self.out_array = out_array\n",
    "        \n",
    "        self.coding = np.zeros(self.length)\n",
    "        for f in self.record.features:\n",
    "            if f.type == \"CDS\":\n",
    "                start = f.location.start\n",
    "                end = f.location.end\n",
    "                self.coding[start: end + 1] = 1 \n",
    "                \n",
    "        \n",
    "        \n",
    "        diff = np.zeros(self.length)\n",
    "        for i in range(self.length):\n",
    "            if not np.array_equal(self.out_array[:, i], self.seq_np[:, i]):\n",
    "                diff[i] = 1\n",
    "        self.diff = diff\n",
    "        \n",
    "        print(\"generated out arrays\")\n",
    "        \n",
    "    def generate_counter(self):\n",
    "        c = self.counter\n",
    "        c[\"all_mist\"] = sum(self.diff)\n",
    "        c[\"mask_mist\"] = sum(self.diff * self.mask)\n",
    "        c[\"free_mist\"] = sum(self.diff) - sum(self.diff * self.mask)\n",
    "        \n",
    "        if c[\"all_mist\"] != c[\"mask_mist\"] + c[\"free_mist\"]:\n",
    "            print(\"error in counter\")\n",
    "        \n",
    "        c[\"coding_mask\"] = sum(self.mask * self.coding)\n",
    "        c[\"noncoding_mask\"] = sum(self.mask) - sum(self.mask * self.coding) \n",
    "        \n",
    "        if c[\"coding_mask\"]+ c[\"noncoding_mask\"] != self.length_mask:\n",
    "            print(\"error in counter\")\n",
    "        \n",
    "        c[\"coding_mask_mist\"] = sum(self.diff * self.mask * self.coding)\n",
    "        c[\"noncoding_mask_mist\"] = sum(self.diff * self.mask) - sum(self.diff * self.mask * self.coding)\n",
    "        \n",
    "        if c[\"coding_mask_mist\"]+c[\"noncoding_mask_mist\"] != c[\"mask_mist\"]:\n",
    "            print(\"error in counter\")\n",
    "        \n",
    "        c[\"mask_part\"] = c[\"mask_mist\"] / self.length_mask\n",
    "        c[\"coding_part\"] = c[\"coding_mask_mist\"] / c[\"coding_mask\"]\n",
    "        c[\"noncoding_part\"] = c[\"noncoding_mask_mist\"] / c[\"noncoding_mask\"]\n",
    "        c[\"baseline_part\"] = c[\"baseline_mean\"] / self.length_mask\n",
    "        c[\"baseline_part_sd\"] = c[\"baseline_sd\"] / self.length_mask\n",
    "        \n",
    "        c[\"free_part\"] = c[\"free_mist\"] / (self.length - self.length_mask)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"generated counter\")\n",
    "    \n",
    "    \n",
    "    def print_results(self, description = \"\"):\n",
    "        if description == \"\":\n",
    "            print(\"no description!\")\n",
    "        \n",
    "        interpretation = (\"mask\\tcoding\\tnoncod\\tfreqs\\t+-\\tfree\")\n",
    "        c = self.counter\n",
    "        results = \"{:.3}\\t{:.3}\\t{:.3}\\t{:.3}\\t{:.3}\\t{:.3}\".format(c[\"mask_part\"],  c[\"coding_part\"], c[\"noncoding_part\"], \n",
    "                                                             c[\"baseline_part\"], c[\"baseline_part_sd\"], c[\"free_part\"])\n",
    "        print(interpretation)\n",
    "        print(results)\n",
    "\n",
    "        file = open(\"data/nnet_results.txt\", \"+a\")\n",
    "        file.write(\"#{}\\tlength\\tmask\\t{}\\n\".format(interpretation, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "        file.write(\"{}\\t{}\\t{}\\t{}\\n\".format(results, self.length, self.length_mask, description))\n",
    "        file.close()\n",
    "        \n",
    "        file = open(\"data/nnet_log.txt\", \"+a\")\n",
    "        file.write(\"#{}\\n\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "        file.write(\"{}\\tlength\\tmask\\n\".format(interpretation))\n",
    "        file.write(\"{}\\t{}\\t{}\\t{}\\n\".format(results, self.length, self.length_mask, description))\n",
    "        file.write(\"{}\\n\".format(self.counter))\n",
    "        file.close()\n",
    "    \n",
    "        self.title = \"{}\\n{}\\t{}\\n{}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), self.length, self.length_mask, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container created\n",
      "read seq from file data/myco_genome.gbff, length = 4411532\n",
      "generated seq for analysis, length = 100000\n",
      "generated mask with 9532 spots of 1 bp, seed True\n"
     ]
    }
   ],
   "source": [
    "container = Container()\n",
    "container.read_seq(remote_genome)\n",
    "container.generate_seq(length = 100000)\n",
    "container.generate_mask(seed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 646788\n",
      "Starting optimization with ADAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/litvinanna/.local/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 00029    Loss 0.165206 \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "i = 0\n",
    "out_np, loss = inpainting(container, cuda=False, iterations = 500)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\ntime: {:.3}s\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.inpaint(out_np)\n",
    "container.baseline()\n",
    "container.generate_out()\n",
    "container.generate_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.print_results(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.title(container.title)\n",
    "plt.savefig(\"data/loss_{}.png\".format(datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(remote_genome, \"genbank\")\n",
    "record = next(iterator)\n",
    "    \n",
    "# print(record.annotations.keys())\n",
    "# print(record.features[0].type)\n",
    "# print(dir(record.features[5].location))\n",
    "# print(record.features[5].location.start)\n",
    "# for f in record.features:\n",
    "#     print(f.type)\n",
    "#     print(f.location.start)\n",
    "\n",
    "print(len(record.seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(10)\n",
    "x[1:3] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Container()\n",
    "a.diff   = np.array([1, 1, 1, 0, 0])\n",
    "a.mask   = np.array([1, 1, 1, 1, 1])\n",
    "a.coding = np.array([1, 0, 0, 0, 0])\n",
    "a.length_mask = sum(a.mask)\n",
    "a.generate_counter()\n",
    "a.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {}\n",
    "c['1']='a'\n",
    "b = c\n",
    "b['2'] = 'b'\n",
    "c['3'] = 'c'\n",
    "b ['4'] ='d'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
