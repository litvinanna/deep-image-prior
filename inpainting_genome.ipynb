{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAKING PICTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#copyed from common_utils to change here\n",
    "def optimize(optimizer_type, parameters, closure, LR, num_iter, inpaintinglog):\n",
    "    \"\"\"Runs optimization loop.\n",
    "\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam' #no change\n",
    "        parameters: list of Tensors to optimize over ## \n",
    "        closure: function, that returns loss variable #no change\n",
    "        LR: learning rate #no change\n",
    "        num_iter: number of iterations  #no change\n",
    "    \"\"\"\n",
    "    if optimizer_type == 'adam':\n",
    "        print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "        for j in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "#             closure()\n",
    "            closure(j, inpaintinglog)\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def inpainting(container, cuda = False, iterations = 100, inpaintinglog = None):\n",
    "    \n",
    "    seq_np = container.seq_np\n",
    "    mask_np = container.mask_np\n",
    "\n",
    "    if cuda: \n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark =True\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        torch.backends.cudnn.enabled = False\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    PLOT = False\n",
    "    imsize = -1\n",
    "    dim_div_by = 64\n",
    "\n",
    "    NET_TYPE = 'skip_depth6'\n",
    "    pad = 'reflection' # 'zero'\n",
    "    OPT_OVER = 'net'\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    INPUT = 'noise'\n",
    "    input_depth = 32\n",
    "    LR = 0.01 \n",
    "    num_iter = iterations\n",
    "    param_noise = False\n",
    "    show_every = 5\n",
    "    figsize = 5 #????\n",
    "    reg_noise_std = 0.03\n",
    "\n",
    "    net = skip(input_depth, seq_np.shape[0], #change skip function in models/skip.py\n",
    "               num_channels_down = [128] * 3,\n",
    "               num_channels_up =   [128] * 3,\n",
    "               num_channels_skip =    [128] * 3,  \n",
    "               filter_size_up = 3, filter_size_down = 3, \n",
    "               upsample_mode='nearest', filter_skip_size=1,\n",
    "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "    \n",
    "\n",
    "    net = net.type(dtype) \n",
    "    net_input = get_noise(input_depth, INPUT, seq_np.shape[1]).type(dtype) #tensor \n",
    "\n",
    "    \n",
    "    s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "    print ('Number of params: %d' % s)\n",
    "    \n",
    "    if inpaintinglog != None:\n",
    "        inpaintinglog.add_net_parameters([NET_TYPE, pad, OPT_OVER, OPTIMIZER, INPUT, \n",
    "                                     input_depth, LR, reg_noise_std, num_iter, cuda, s])\n",
    "        inpaintinglog.init_log()\n",
    "\n",
    "\n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "    img_var = np_to_torch(seq_np).type(dtype)\n",
    "    mask_var = np_to_torch(mask_np).type(dtype)\n",
    "    \n",
    "    def closure(i, inpaintinglog):\n",
    "    #     if param_noise:\n",
    "    #         for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "    #             n = n + n.detach().clone().normal_() * n.std() / 50\n",
    "\n",
    "        net_input = net_input_saved\n",
    "        if reg_noise_std > 0:\n",
    "            net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        out = net(net_input)\n",
    "  \n",
    "        total_loss = mse(out * mask_var, img_var * mask_var)\n",
    "        total_loss.backward()\n",
    "        print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
    "        \n",
    "        if inpaintinglog != None:\n",
    "            inpaintinglog.loss.append(total_loss)\n",
    "            if i % inpaintinglog.out_nps_every == 0:\n",
    "                out_np = torch_to_np(out)\n",
    "                inpaintinglog.compare_log(i, out_np)\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    p = get_params(OPT_OVER, net, net_input) # list of tensors to optimize over !! in optimize\n",
    "    \n",
    "    start_time = time.time()\n",
    "    optimize(OPTIMIZER, p, closure, LR, num_iter, inpaintinglog) # optimize is in utils/common.utils\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"\\ntime: {}s\".format(elapsed_time))\n",
    "    \n",
    "    out_np = torch_to_np(net(net_input))\n",
    "    \n",
    "    return out_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import PIL\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import random \n",
    "\n",
    "from Bio import SeqIO\n",
    "import math\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fasta_file = \"data/myco_genome.fasta\"\n",
    "local_genome = \"/Users/pochtalionizm/Projects/neuro/data/vibrio.gbff\"\n",
    "remote_genome = \"data/myco_genome.gbff\"\n",
    "myco = \"/Users/pochtalionizm/Projects/neuro/data/myco.gbff\"\n",
    "vibrio = \"/Users/pochtalionizm/Projects/neuro/data/vibrio.gbff\"\n",
    "homo = \"/Users/pochtalionizm/Projects/neuro/data/homos_2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inpaintinglog():\n",
    "    def __init__(self, container = None, every = 1000):\n",
    "        self.datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        self.loss = []\n",
    "        self.runtime = None\n",
    "        self.out_nps = []\n",
    "        self.out_nps_every = every\n",
    "        self.net_parameters = None\n",
    "        self.net_description = None\n",
    "        \n",
    "        self.log_f = \"data/\" + self.datetime + \"_\" + container.short_title\n",
    "        self.container = container\n",
    "        self.seq_description = container.title\n",
    "\n",
    "        self.counters = []\n",
    "        self.keys = [\"mask_part\", \"coding_part\", \"noncoding_part\", \"free_part\"]\n",
    "        self.net_keys = [\"NET_TYPE\", \"pad\", \"OPT_OVER\", \"OPTIMIZER\", \"INPUT\", \"input_depth\", \"LR\", \"reg_noise_std\",\n",
    "                         \"num_iter\", \"cuda\", \"num_parameters\"]\n",
    "        if not os.path.isdir(self.log_f):\n",
    "            os.mkdir(self.log_f)\n",
    "    \n",
    "    def add_net_parameters(self, p):\n",
    "        self.net_parameters = {self.net_keys[i]:p[i] for i in range(11)}\n",
    "        self.num_iter = p[8]\n",
    "        self.net_description = \",\".join([str(x) for x in p])\n",
    "        self._generate_titles()\n",
    "        \n",
    "    def _generate_titles(self):\n",
    "        it = self.net_parameters[\"num_iter\"]\n",
    "        self.file_title = \"{}_{}_{}\".format(self.datetime, self.seq_description, it)\n",
    "        self.plot_title = \"{}\\n{}\\n{}\".format(self.datetime, self.seq_description, self.net_description)\n",
    "        \n",
    "    \n",
    "    def plot_loss(self, save = False):\n",
    "        fig = plt.plot(self.loss)\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('iteration')\n",
    "        plt.title(self.plot_title)\n",
    "        plt.tight_layout()\n",
    "        if save:\n",
    "            plt.savefig(\"pics/loss_{}.png\".format(self.file_title))\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def init_log(self):\n",
    "        file = open(self.log_f + \"/info.txt\", \"+a\")\n",
    "        file.write(self.datetime + \"\\n\") \n",
    "        file.write(self.net_description + \"\\n\") \n",
    "        file.write(self.seq_description + \"\\n\")\n",
    "        file.close()\n",
    "        np.save(self.log_f + \"/seq_np.npy\", container.seq_np)\n",
    "        np.save(self.log_f + \"/mask.npy\", container.mask)\n",
    "        \n",
    "    \n",
    "    def compare_log(self, i, out_np):\n",
    "        self.out_nps.append(out_np)\n",
    "        np.save(\"{}/{:05d}_out_np.npy\".format(self.log_f, i), out_np)\n",
    "    \n",
    "\n",
    "#     def compare_log(self, i, out_np):\n",
    "#         self.out_nps.append(out_np)\n",
    "        \n",
    "#         file = open(self.log_file, \"+a\")\n",
    "#         file.write(\"{:05d}\\t\".format(i))\n",
    "#         counter = compare(self.container, out_np)\n",
    "#         self.counters.append(counter)\n",
    "#         for key in self.keys:\n",
    "#             file.write(\"{:.5f}\\t\".format(counter[key]))\n",
    "#         file.write(\"\\n\")\n",
    "#         file.close()\n",
    "\n",
    "#     def read_loglines(self, datetime):\n",
    "#         file = open(self.log_file, \"r\")\n",
    "#         loglines = []\n",
    "#         read = False\n",
    "#         for line in file.readlines():\n",
    "#             if line.startswith(\"#net\"):\n",
    "#                 read = False\n",
    "#                 if line.split('\\t')[1] == datetime:\n",
    "#                     read = True \n",
    "#             if read:\n",
    "#                 loglines.append(line)\n",
    "                \n",
    "#         if len(loglines) == 0:\n",
    "#             print(\"not found\")\n",
    "#             return None\n",
    "#         file.close()\n",
    "#         return loglines\n",
    "    \n",
    "        \n",
    "#     def _unzip(self, loglines):\n",
    "#         self.datetime = loglines[0].split('\\t')[1] \n",
    "#         self.net_info = loglines[0]\n",
    "#         self.seq_info = loglines[1]\n",
    "#         self.out_nps_every =  int(loglines[4].split('\\t')[0]) - int(loglines[3].split('\\t')[0])\n",
    "#         for i in range(3, len(loglines)):\n",
    "#             numbers = loglines[i].split('\\t')\n",
    "#             c = {}\n",
    "#             for i in range(4):\n",
    "#                 c[self.keys[i]] = float(numbers[i+1])\n",
    "#             self.counters.append(c)\n",
    "#         self.net_description = self.net_info.split('\\t')[2]\n",
    "#         self.net_parameters = {self.net_keys[i]:self.net_description.split(',')[i] for i in range(len(self.net_keys))}\n",
    "#         self.seq_description = self.seq_info.split('\\t')[1]\n",
    "#         self._generate_titles()\n",
    "\n",
    "\n",
    "# def read_log(file = \"data/nnet_log.txt\"):\n",
    "#     file = open(file, \"r\")\n",
    "#     loglines = []\n",
    "#     for line in file.readlines():\n",
    "#         if line.startswith(\"#net\"):\n",
    "#                 if loglines != []:\n",
    "#                     inpaintinglog = Inpaintinglog()\n",
    "#                     inpaintinglog._unzip(loglines)\n",
    "#                     yield inpaintinglog\n",
    "#                 loglines = []\n",
    "#         loglines.append(line)\n",
    "#     yield inpaintinglog\n",
    "#     file.close()       \n",
    "\n",
    "    \n",
    "        \n",
    "class Container:\n",
    "    def __init__(self):\n",
    "        print(\"...\", end = \"\\r\")\n",
    "        self.record = None #Seqrecord\n",
    "        self.length = None #int\n",
    "        self.seq = None #np.array of chars\n",
    "        self.seq_np = None #np.array of [1, 0, 0, 0]\n",
    "#         self.out_seq = None #np.array of chars\n",
    "#         self.out_array = None #np.array of [1, 0, 0, 0]\n",
    "        \n",
    "        \n",
    "        self.bases_dict     = {\"A\": 0, \"T\": 1, \"C\": 2, \"G\": 3}\n",
    "        self.bases_list = [\"A\", \"T\", \"C\", \"G\"]\n",
    "        self.bases_np        = {\n",
    "                                \"A\": np.array([1, 0, 0, 0], dtype = np.float32),\n",
    "                                \"T\": np.array([0, 1, 0, 0], dtype = np.float32),\n",
    "                                \"C\": np.array([0, 0, 1, 0], dtype = np.float32),\n",
    "                                \"G\": np.array([0, 0, 0, 1], dtype = np.float32)\n",
    "                            }\n",
    "        self.freqs = None # dict {'A':0.34, ...}\n",
    "        self.counter = {}\n",
    "        self.inpaintinglog = None\n",
    "        self.title = None\n",
    "        print(\"container created\")\n",
    "        \n",
    "        \n",
    "    def read_seq(self, genome_file = remote_genome, genome_file_type = \"genbank\"):\n",
    "        print(\"...\", end = \"\\r\")\n",
    "        iterator = SeqIO.parse(genome_file, genome_file_type)\n",
    "        self.record = next(iterator)\n",
    "        print(\"read seq from file {}, length = {}\".format(genome_file, len(self.record.seq)))\n",
    "    \n",
    "    def cut_seq(self, length = None, start = None):\n",
    "        print(\"...\", end = \"\\r\")\n",
    "        self.seq = np.asarray(self.record.seq[start:start+length]) \n",
    "        self.length = length\n",
    "        self.start = start\n",
    "        length_genome = len(self.record.seq)\n",
    "        self.genome_part = ( start/length_genome*100, (start+length)/length_genome*100)\n",
    "        \n",
    "        self.short_title = \"{:.1f}-{:.1f}_\".format(self.genome_part[0], self.genome_part[1])\n",
    "        self.title = \"{:07d}_{:09d}_{:.1f}-{:.1f}_\".format(self.length, self.start, self.genome_part[0], self.genome_part[1])\n",
    "        print(\"cuted seq for analysis, length = {}, start = {}, part = {:.1f}-{:.1f}\".format(self.length, self.start,\n",
    "                                                                                              self.genome_part[0], \n",
    "                                                                                              self.genome_part[1] \n",
    "                                                                                              ))\n",
    "        \n",
    "    def generate_seq(self):\n",
    "        print(\"...\", end = \"\\r\")\n",
    " \n",
    "        seq_np = np.zeros((4, self.length), dtype = np.float32) \n",
    "        for index in range(self.length):\n",
    "            base = self.seq[index]\n",
    "            if base in self.bases_list:\n",
    "                channel = self.bases_dict[base]\n",
    "                seq_np[channel][index] = 1\n",
    "            else:\n",
    "                print(\"alternative base\")\n",
    "        self.seq_np = seq_np\n",
    "        \n",
    "        print(\"generated seq_np\")\n",
    "        \n",
    "        \n",
    "    def generate_mask(self, seed=None):\n",
    "        print(\"...\", end = \"\\r\")\n",
    "        length = self.length\n",
    "        length_mask = math.ceil(self.length * 0.1)\n",
    "        \n",
    "        if seed != None:\n",
    "            random.seed(seed)\n",
    "        mask_np = np.zeros((4, length), dtype=np.float32)\n",
    "        mask = np.zeros(length)\n",
    "        \n",
    "        mask_np.fill(1)\n",
    "        for n in range(length_mask):\n",
    "            spot = 1\n",
    "            index = random.randint(0, length-spot)\n",
    "            for i in range(index, index+spot):\n",
    "                mask_np[:, i] = [0,0,0,0]\n",
    "                mask[i] = 1\n",
    "                \n",
    "        self.mask_np = mask_np\n",
    "        self.length_mask = int(sum(mask)) # true mask length!!\n",
    "        self.mask = mask\n",
    "        self.short_title = self.short_title + '_'.join(self.record.description.split(' ')[0:2])\n",
    "        self.title = self.title + \"{}_{}\".format(self.length_mask, '_'.join(self.record.description.split(' ')))\n",
    "\n",
    "        print(\"generated mask with {} spots of {} bp\".format(self.length_mask, spot))          \n",
    "    \n",
    "    def _get_freqs(self):\n",
    "        counter = Counter(self.seq[0:self.length])\n",
    "        self.freqs = {letter : value / self.length for (letter, value) in counter.items()}\n",
    "    \n",
    "    def _baseline(self): #count mistakes under mask if using random predictor with frequences\n",
    "        counter = 0\n",
    "        for i in range(self.length):\n",
    "            if self.mask[i] == 1: #if its under mask\n",
    "                w = [self.freqs[x] for x in self.bases_list]\n",
    "                letter = random.choices(self.bases_list, weights=w)[0]\n",
    "                if letter != self.seq[i]:\n",
    "                        counter +=1\n",
    "        return counter\n",
    "    \n",
    "    \n",
    "    def baseline(self):\n",
    "        self._get_freqs()\n",
    "        baselines = []\n",
    "        for i in range(200):\n",
    "            print(\"{:03d}/200\".format(i), end = \"\\r\")\n",
    "            baselines.append(self._baseline())\n",
    "        mean = np.mean(baselines)\n",
    "        sd = np.std(baselines)\n",
    "        self.counter[\"baseline_mean\"] = mean\n",
    "        self.counter[\"baseline_sd\"] = sd\n",
    "        c = self.counter\n",
    "        c[\"baseline_part\"] = c[\"baseline_mean\"] / self.length_mask\n",
    "        c[\"baseline_part_sd\"] = c[\"baseline_sd\"] / self.length_mask\n",
    "        print(\"got baseline\")\n",
    "\n",
    "        \n",
    "def compare(seq_np, out_np):\n",
    "    \n",
    "    if len(seq_np) != len(out_np):\n",
    "        print(\"error\")\n",
    "        return None\n",
    "    \n",
    "    length = len(seq_np[0])\n",
    "\n",
    "    out_array = np.zeros((4,length)) #array analog to seq_np\n",
    "    for i in range(length):\n",
    "        n = np.argmax(out_np[:, i])\n",
    "        out_array[n, i] = 1\n",
    "            \n",
    "    diff = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if not np.array_equal(out_array[:, i], seq_np[:, i]):\n",
    "            diff[i] = 1\n",
    "    return diff \n",
    "            \n",
    "def generate_counter(diff, mask, coding):\n",
    "    c = {}\n",
    "    c[\"all_mist\"] = sum(diff)\n",
    "    c[\"mask_mist\"] = sum(diff * mask)\n",
    "    c[\"free_mist\"] = sum(diff) - sum(diff * mask)\n",
    "\n",
    "    if c[\"all_mist\"] != c[\"mask_mist\"] + c[\"free_mist\"]:\n",
    "        print(\"error in counter\")\n",
    "\n",
    "    c[\"coding_mask\"] = sum(mask * coding)\n",
    "    c[\"noncoding_mask\"] = sum(mask) - sum(mask * coding) \n",
    "\n",
    "    if c[\"coding_mask\"]+ c[\"noncoding_mask\"] != length_mask:\n",
    "        print(\"error in counter\")\n",
    "\n",
    "    c[\"coding_mask_mist\"] = sum(diff * mask * coding)\n",
    "    c[\"noncoding_mask_mist\"] = sum(diff * mask) - sum(diff * mask * coding)\n",
    "\n",
    "    if c[\"coding_mask_mist\"]+c[\"noncoding_mask_mist\"] != c[\"mask_mist\"]:\n",
    "        print(\"error in counter\")\n",
    "        \n",
    "    c[\"mask_part\"] = c[\"mask_mist\"] / length_mask\n",
    "    c[\"free_part\"] = c[\"free_mist\"] / (length - length_mask)\n",
    "    \n",
    "    c[\"coding_part\"] = c[\"coding_mask_mist\"] / c[\"coding_mask\"]\n",
    "    c[\"noncoding_part\"] = c[\"noncoding_mask_mist\"] / c[\"noncoding_mask\"]\n",
    "        \n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(homo, \"fasta\")\n",
    "record = next(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = Container()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.record = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.cut_seq(start = 6000000, length = 2000)\n",
    "container.generate_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.generate_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaintinglog = Inpaintinglog(container, every = 50)\n",
    "i = 0\n",
    "inpainting(container, iterations = 51, inpaintinglog = inpaintinglog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\r",
      "container created\n"
     ]
    }
   ],
   "source": [
    "path = \"data/2019-02-23_16:18:26_2.5-2.5_NC_000002.12_Homo\"\n",
    "c1 = Container()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.seq_np = np.load(path + \"/seq_np.npy\")\n",
    "c1.mask = np.load(path + \"/mask.npy\")\n",
    "out_np = np.load(path + \"/00050_out_np.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = open(path + \"/info.txt\", \"r\")\n",
    "datetime = info.readline()\n",
    "net_desc = info.readline()\n",
    "seq_desc = info.readline().split(\"_\")\n",
    "c1.length = int(seq_desc[0])\n",
    "c1.start = int(seq_desc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (__init__.py, line 500)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3267\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-f0e75c3963e0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from track import track\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/pochtalionizm/Projects/neuro/track/track/__init__.py\"\u001b[0;36m, line \u001b[0;32m500\u001b[0m\n\u001b[0;31m    else: raise TypeError, 'The following selection parameter: \"' + selection + '\" was not understood.'\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacterial part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = Container()\n",
    "container.read_seq(myco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 9\n",
    "container.generate_seq(length = 100000, seed = s)\n",
    "container.generate_mask(seed = s)\n",
    "print(container.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaintinglog = Inpaintinglog(container, every = 50)\n",
    "i = 0\n",
    "inpainting(container, inpaintinglog, cuda=False, iterations = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpaintinglog.plot_loss(True)\n",
    "# coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "# noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "# mask = [c['mask_part'] for c in inpaintinglog.counters]\n",
    "# plot_part(coding, \"coding\")\n",
    "# plot_part(noncoding, \"noncoding\")\n",
    "# plot_part(mask, \"mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inpaintinglog in read_log():\n",
    "# #     print(inpaintinglog.seq_info)\n",
    "#     coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "#     noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "#     mask = [c['mask_part'] for c in inpaintinglog.counters]\n",
    "#     plot_part(coding, \"coding\")\n",
    "#     plot_part(noncoding, \"noncoding\")\n",
    "#     plot_part(mask, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "mask = [c['mask_part'] for c in inpaintinglog.counters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_part(coding, name):\n",
    "    fig = plt.plot(coding)\n",
    "    plt.ylim(0.65, 0.75)\n",
    "    plt.ylabel('mistakes in {} part'.format(name))\n",
    "    plt.xlabel('iteration/{}'.format(inpaintinglog.out_nps_every))\n",
    "    plt.title(inpaintinglog.plot_title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pics/{}_{}.png\".format(inpaintinglog.file_title, name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_part(coding, \"coding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_part(noncoding, \"noncoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_part(mask, \"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(myco, \"genbank\")\n",
    "record = next(iterator)\n",
    "length = (len(record.seq))\n",
    "# # print(record.annotations.keys())\n",
    "# # print(record.features[0].type)\n",
    "# # print(dir(record.features[5].location))\n",
    "# # print(record.features[5].location.start)\n",
    "          \n",
    "coding = np.zeros(length)\n",
    "for f in record.features:\n",
    "    if f.type == \"CDS\":\n",
    "        f_start = f.location.start\n",
    "        f_end = f.location.end\n",
    "        coding[f_start: f_end] = 1 \n",
    "\n",
    "cds = []\n",
    "non = []\n",
    "previous_value = 2\n",
    "last_switch_i = 0\n",
    "for i in range(length + 1):\n",
    "    if i == length:\n",
    "        current_value = 2\n",
    "    else:\n",
    "        current_value = coding[i]\n",
    "        \n",
    "    if current_value != previous_value:\n",
    "#         print(\"switch at {}\".format(i))\n",
    "        l = i - last_switch_i\n",
    "#         print(l)\n",
    "        if current_value == 1:\n",
    "            cds.append(l)\n",
    "        else:\n",
    "            non.append(l)\n",
    "        last_switch_i = i\n",
    "    previous_value = current_value\n",
    "              \n",
    "# print('_'.join(record.description.split(' ')[0:3])\n",
    "print(sum(coding))\n",
    "print(sum(cds) + sum (non))\n",
    "print(len(record.seq))\n",
    "print(np.mean(cds), len(cds), sum(cds))\n",
    "print(np.mean(non), len(non), sum(non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(homo, \"fasta\")\n",
    "record = next(iterator)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
