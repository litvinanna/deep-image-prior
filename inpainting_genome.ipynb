{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#copyed from common_utils to change here\n",
    "def optimize(optimizer_type, parameters, closure, LR, num_iter, inpaintinglog):\n",
    "    \"\"\"Runs optimization loop.\n",
    "\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam' #no change\n",
    "        parameters: list of Tensors to optimize over ## \n",
    "        closure: function, that returns loss variable #no change\n",
    "        LR: learning rate #no change\n",
    "        num_iter: number of iterations  #no change\n",
    "    \"\"\"\n",
    "    if optimizer_type == 'adam':\n",
    "        print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "        for j in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "#             closure()\n",
    "            closure(j, inpaintinglog)\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def inpainting(container, cuda = False, iterations = 100, inpaintinglog = None):\n",
    "    \n",
    "    seq_np = container.seq_np\n",
    "    mask_np = container.mask_np\n",
    "\n",
    "    if cuda: \n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark =True\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        torch.backends.cudnn.enabled = False\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    PLOT = False\n",
    "    imsize = -1\n",
    "    dim_div_by = 64\n",
    "\n",
    "    NET_TYPE = 'skip_depth6'\n",
    "    pad = 'reflection' # 'zero'\n",
    "    OPT_OVER = 'net'\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    INPUT = 'noise'\n",
    "    input_depth = 32\n",
    "    LR = 0.01 \n",
    "    num_iter = iterations\n",
    "    param_noise = False\n",
    "    show_every = 5\n",
    "    figsize = 5 #????\n",
    "    reg_noise_std = 0.03\n",
    "    \n",
    "    num_channels_down = [128] * 3\n",
    "    num_channels_up =   [128] * 3\n",
    "    num_channels_skip =  [128] * 3 \n",
    "    filter_size_up = 3\n",
    "    filter_size_down = 3\n",
    "    upsample_mode='nearest'\n",
    "    filter_skip_size=1\n",
    "    need_sigmoid=True\n",
    "    need_bias=True \n",
    "    pad=pad\n",
    "    act_fun='LeakyReLU'\n",
    "\n",
    "\n",
    "    net = skip(input_depth, seq_np.shape[0], #change skip function in models/skip.py\n",
    "               num_channels_down,\n",
    "               num_channels_up,\n",
    "               num_channels_skip,  \n",
    "               filter_size_up, filter_size_down, \n",
    "               upsample_mode, filter_skip_size,\n",
    "               need_sigmoid, need_bias, pad, act_fun).type(dtype)\n",
    "    \n",
    "\n",
    "    net = net.type(dtype) \n",
    "    net_input = get_noise(input_depth, INPUT, seq_np.shape[1]).type(dtype) #tensor \n",
    "\n",
    "    \n",
    "    s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "    print ('Number of params: %d' % s)\n",
    "    \n",
    "    if inpaintinglog != None:\n",
    "        inpaintinglog.add_net_parameters([NET_TYPE, pad, OPT_OVER, OPTIMIZER, INPUT, \n",
    "                                     input_depth, LR, reg_noise_std, num_iter, cuda, s,\n",
    "                                        num_channels_down,\n",
    "                                       num_channels_up,\n",
    "                                       num_channels_skip,  \n",
    "                                       filter_size_up, filter_size_down, \n",
    "                                       upsample_mode, filter_skip_size,\n",
    "                                       need_sigmoid, need_bias, pad, act_fun])\n",
    "\n",
    "        inpaintinglog.init_log()\n",
    "\n",
    "\n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "    img_var = np_to_torch(seq_np).type(dtype)\n",
    "    mask_var = np_to_torch(mask_np).type(dtype)\n",
    "    \n",
    "    def closure(i, inpaintinglog):\n",
    "    #     if param_noise:\n",
    "    #         for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "    #             n = n + n.detach().clone().normal_() * n.std() / 50\n",
    "\n",
    "        net_input = net_input_saved\n",
    "        if reg_noise_std > 0:\n",
    "            net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        out = net(net_input)\n",
    "  \n",
    "        total_loss = mse(out * mask_var, img_var * mask_var)\n",
    "        total_loss.backward()\n",
    "        print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
    "        \n",
    "        if inpaintinglog != None:\n",
    "            inpaintinglog.loss.append(total_loss)\n",
    "            if i % inpaintinglog.out_nps_every == 0:\n",
    "                out_np = torch_to_np(out)\n",
    "                inpaintinglog.compare_log(i, out_np)\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    p = get_params(OPT_OVER, net, net_input) # list of tensors to optimize over !! in optimize\n",
    "    \n",
    "    start_time = time.time()\n",
    "    optimize(OPTIMIZER, p, closure, LR, num_iter, inpaintinglog) # optimize is in utils/common.utils\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"\\ntime: {}s\".format(elapsed_time))\n",
    "    \n",
    "    out_np = torch_to_np(net(net_input))\n",
    "    inpaintinglog.end_log()\n",
    "    \n",
    "    return out_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import PIL\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import random \n",
    "\n",
    "from Bio import SeqIO\n",
    "import math\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fasta_file = \"data/myco_genome.fasta\"\n",
    "local_genome = \"/Users/pochtalionizm/Projects/neuro/data/vibrio.gbff\"\n",
    "remote_genome = \"data/myco_genome.gbff\"\n",
    "myco = \"/Users/pochtalionizm/Projects/neuro/data/myco.gbff\"\n",
    "vibrio = \"/Users/pochtalionizm/Projects/neuro/data/vibrio.gbff\"\n",
    "homo = \"data/homos_2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/pochtalionizm/Projects/neuro/tools/\")\n",
    "from sequence_for_nn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(\"data/homos_2.fasta\", \"fasta\")\n",
    "record = next(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\r",
      "container created\n"
     ]
    }
   ],
   "source": [
    "container = Container()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.record = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuted seq for analysis, length = 500000, start = 6500000, part = 2.7-2.9\n",
      "generated seq_np\n"
     ]
    }
   ],
   "source": [
    "container.cut_seq(start = 6500000, length = 500000)\n",
    "container.generate_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\r",
      "generated mask with 47561 spots of 1 bp\n"
     ]
    }
   ],
   "source": [
    "container.generate_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 646788\n",
      "Starting optimization with ADAM\n",
      "Iteration 02720    Loss 0.167892 \r"
     ]
    }
   ],
   "source": [
    "inpaintinglog = Inpaintinglog(container, every = 4000)\n",
    "i = 0\n",
    "inpainting(container, iterations = 4001, inpaintinglog = inpaintinglog, cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacterial part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = Container()\n",
    "container.read_seq(myco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 9\n",
    "container.generate_seq(length = 100000, seed = s)\n",
    "container.generate_mask(seed = s)\n",
    "print(container.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaintinglog = Inpaintinglog(container, every = 50)\n",
    "i = 0\n",
    "inpainting(container, inpaintinglog, cuda=False, iterations = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpaintinglog.plot_loss(True)\n",
    "# coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "# noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "# mask = [c['mask_part'] for c in inpaintinglog.counters]\n",
    "# plot_part(coding, \"coding\")\n",
    "# plot_part(noncoding, \"noncoding\")\n",
    "# plot_part(mask, \"mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inpaintinglog in read_log():\n",
    "# #     print(inpaintinglog.seq_info)\n",
    "#     coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "#     noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "#     mask = [c['mask_part'] for c in inpaintinglog.counters]\n",
    "#     plot_part(coding, \"coding\")\n",
    "#     plot_part(noncoding, \"noncoding\")\n",
    "#     plot_part(mask, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = [c['coding_part'] for c in inpaintinglog.counters]\n",
    "noncoding = [c['noncoding_part'] for c in inpaintinglog.counters]\n",
    "mask = [c['mask_part'] for c in inpaintinglog.counters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_part(coding, name):\n",
    "    fig = plt.plot(coding)\n",
    "    plt.ylim(0.65, 0.75)\n",
    "    plt.ylabel('mistakes in {} part'.format(name))\n",
    "    plt.xlabel('iteration/{}'.format(inpaintinglog.out_nps_every))\n",
    "    plt.title(inpaintinglog.plot_title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pics/{}_{}.png\".format(inpaintinglog.file_title, name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_part(coding, \"coding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_part(noncoding, \"noncoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_part(mask, \"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(myco, \"genbank\")\n",
    "record = next(iterator)\n",
    "length = (len(record.seq))\n",
    "# # print(record.annotations.keys())\n",
    "# # print(record.features[0].type)\n",
    "# # print(dir(record.features[5].location))\n",
    "# # print(record.features[5].location.start)\n",
    "          \n",
    "coding = np.zeros(length)\n",
    "for f in record.features:\n",
    "    if f.type == \"CDS\":\n",
    "        f_start = f.location.start\n",
    "        f_end = f.location.end\n",
    "        coding[f_start: f_end] = 1 \n",
    "\n",
    "cds = []\n",
    "non = []\n",
    "previous_value = 2\n",
    "last_switch_i = 0\n",
    "for i in range(length + 1):\n",
    "    if i == length:\n",
    "        current_value = 2\n",
    "    else:\n",
    "        current_value = coding[i]\n",
    "        \n",
    "    if current_value != previous_value:\n",
    "#         print(\"switch at {}\".format(i))\n",
    "        l = i - last_switch_i\n",
    "#         print(l)\n",
    "        if current_value == 1:\n",
    "            cds.append(l)\n",
    "        else:\n",
    "            non.append(l)\n",
    "        last_switch_i = i\n",
    "    previous_value = current_value\n",
    "              \n",
    "# print('_'.join(record.description.split(' ')[0:3])\n",
    "print(sum(coding))\n",
    "print(sum(cds) + sum (non))\n",
    "print(len(record.seq))\n",
    "print(np.mean(cds), len(cds), sum(cds))\n",
    "print(np.mean(non), len(non), sum(non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "iterator = SeqIO.parse(homo, \"fasta\")\n",
    "record = next(iterator)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 32, 64, 128, 128, 128]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
